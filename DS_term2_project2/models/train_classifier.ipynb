{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Questions:\n",
    "\n",
    "From udacity rubrics:\n",
    "-    Go into more detail about the dataset and your data cleaning and modeling process in your README file, add screenshots of your web app and model results.\n",
    "-    Add more visualizations to the web app.\n",
    "-    Based on the categories that the ML algorithm classifies text into, advise some organizations to connect to.\n",
    "-    Customize the design of the web app.\n",
    "-    Deploy the web app to a cloud service provider.\n",
    "-    Improve the efficiency of the code in the ETL and ML pipeline.\n",
    "-    This dataset is imbalanced (ie some labels like water have few examples). In your README, discuss how this imbalance, how that affects training the model, and your thoughts about emphasizing precision or recall for the various categories.\n",
    "\n",
    "From my view:\n",
    "- (tag: Tech) How to deal with different expressions which share the same meaning to compress datasets? Word embedding? N-gram model?\n",
    "- (tag: Tech) How to visualize the comprehension of model?\n",
    "- (tag: Tech) How to measure the ability of model generalization?\n",
    "- (tag: Business) This model is suitable for Figure Eight, show me the reasons :)\n",
    "- (tag: Business) If applied, what is needed to make sure the  normal operation of this model? How to evaluate the cost of potential necessary changes occured in company like staff structure, financial?\n",
    "- (tag: Business) Draw a data transportation map(like from client to host, from host to company staff), find out the most time-consuming transportation line and try to optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# TODO 2019/3/8: reload all libraries\n",
    "\n",
    "\n",
    "import re, sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger', 'brown'])\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, TweetTokenizer \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import brown\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from lightgbm)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from lightgbm)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from lightgbm)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterResponse2.db')\n",
    "df = pd.read_sql(\"SELECT * FROM DisasterResponse2\", engine)\n",
    "X = df[\"message\"]\n",
    "Y = df.drop([\"id\", \"message\", \"original\", \"genre\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Weather update - a cold front from Cuba that c...\n",
       "1                  Is the Hurricane over or is it not over\n",
       "2                          Looking for someone but no name\n",
       "3        UN reports Leogane 80-90 destroyed. Only Hospi...\n",
       "4        says: west side of Haiti, rest of the country ...\n",
       "5                   Information about the National Palace-\n",
       "6                           Storm at sacred heart of jesus\n",
       "7        Please, we need tents and water. We are in Sil...\n",
       "8          I would like to receive the messages, thank you\n",
       "9        I am in Croix-des-Bouquets. We have health iss...\n",
       "10       There's nothing to eat and water, we starving ...\n",
       "11       I am in Petionville. I need more information r...\n",
       "12       I am in Thomassin number 32, in the area named...\n",
       "13       Let's do it together, need food in Delma 75, i...\n",
       "14       More information on the 4636 number in order f...\n",
       "15       A Comitee in Delmas 19, Rue ( street ) Janvier...\n",
       "16       We need food and water in Klecin 12. We are dy...\n",
       "17       are you going to call me or do you want me to ...\n",
       "18          I don't understand how to use this thing 4636.\n",
       "19       I would like to know if the earthquake is over...\n",
       "20       I would like to know if one of the radio ginen...\n",
       "21                          I'm in Laplaine, I am a victim\n",
       "22       There's a lack of water in Moleya, please info...\n",
       "23       Those people who live at Sibert need food they...\n",
       "24       I want to say hello, my message is to let you ...\n",
       "25                      Can you tell me about this service\n",
       "26       People I'm at Delma 2, we don't anything what ...\n",
       "27       We are at Gressier we needs assistance right a...\n",
       "28       How can we get water and food in Fontamara 43 ...\n",
       "29       We need help. Carrefour has been forgotten com...\n",
       "                               ...                        \n",
       "26186    The ability to pick dengue from influenza is c...\n",
       "26187    A Federation chartered ship arrived from Lae w...\n",
       "26188    The result is that in Aceh province many prefa...\n",
       "26189    Otherwise, the risk is families fleeing again ...\n",
       "26190    A United Nations team from the Electoral Assis...\n",
       "26191    Senegal and Guinea-Bissau have agreed to condu...\n",
       "26192    The President said that her Government always ...\n",
       "26193    It was decided that all vehicle movement from ...\n",
       "26194    The tendency to link deforestation with large ...\n",
       "26195    Polio is a viral disease that attacks the nerv...\n",
       "26196    The new constitution declares that 'Somalia is...\n",
       "26197    We're providing clean water to people who woul...\n",
       "26198    Relief items include towels, sanitary napkins,...\n",
       "26199    In Aceh's Meulaboh town the UN refugee agency ...\n",
       "26200    WHO is recruiting a sanitary engineer / consul...\n",
       "26201    Following the severe floods which occurred ove...\n",
       "26202    The closure has stopped 169 inbound flights an...\n",
       "26203    BANGKOK, 24 January 2012 (NNT) - Prime Ministe...\n",
       "26204    Cadmium, a metallic element widely used in bat...\n",
       "26205    Epidemic surveillance: National Institute of C...\n",
       "26206    2.1 Due to sporadic skirmishes in eastern D.R....\n",
       "26207    No other army had gone to greater lengths to a...\n",
       "26208    The delivery was made in conjunction with the ...\n",
       "26209    However while ECOWAS wanted him to lead a 12-m...\n",
       "26210    Hpakant, an area rich with coveted jade stones...\n",
       "26211    The training demonstrated how to enhance micro...\n",
       "26212    A suitable candidate has been selected and OCH...\n",
       "26213    Proshika, operating in Cox's Bazar municipalit...\n",
       "26214    Some 2,000 women protesting against the conduc...\n",
       "26215    A radical shift in thinking came about as a re...\n",
       "Name: message, Length: 26216, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "1        1        0      0            1             0                 0   \n",
       "2        1        0      0            0             0                 0   \n",
       "3        1        1      0            1             0                 1   \n",
       "4        1        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone      ...        \\\n",
       "0                  0         0         0            0      ...         \n",
       "1                  0         0         0            0      ...         \n",
       "2                  0         0         0            0      ...         \n",
       "3                  0         0         0            0      ...         \n",
       "4                  0         0         0            0      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sent(text):\n",
    "    \"\"\"Tokenizes text row by row from pandas DataFrame.\n",
    "\n",
    "    Tokenizes text by this function combine tokenize method \n",
    "    from nltk package and some self-defined rules. It may fail\n",
    "    when strings out of range of the defined rules occur in text.\n",
    "\n",
    "    Args:\n",
    "        text: A row text data from the relevant column of pandas \n",
    "        DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        A numpy array containing clean tokens extracted from text\n",
    "\n",
    "        \"we were friends, good friends\" --> ['we', 'were', 'friend', 'good', 'friend']\n",
    "\n",
    "    Raises:\n",
    "        None yet\n",
    "    \"\"\"\n",
    "    \n",
    "    url_reg = \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "#     punct_reg = \"[^a-zA-Z0-9@]+\"\n",
    "    punct_reg = \"[^a-zA-Z0-9]+\"\n",
    "    detected_urls = re.findall(url_reg, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "    text = re.sub(punct_reg, \" \", text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    word_tokenizer_tweet = TweetTokenizer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    clean_tokens_list = []\n",
    "    \n",
    "    sentence_list = nltk.sent_tokenize(text)\n",
    "    for sentence in sentence_list:\n",
    "        tokens = word_tokenizer_tweet.tokenize(sentence)\n",
    "        clean_tokens_list.append(\n",
    "            [lemmatizer.lemmatize(tok).strip() for tok in tokens]\n",
    "        )\n",
    "    clean_tokens_list = [lemmatizer.lemmatize(stemmer(tok)).strip() for tok in tokens]  \n",
    "    \n",
    "    # Note 2019/3/7: remove any text followed by  \"@\",  fail because unsolved Error \"TypeError: iteration over a 0-d array\"\n",
    "    clean_tokens_arr = np.array(clean_tokens_list).squeeze()\n",
    "#     func = lambda x: \"@\" in x\n",
    "#     try:\n",
    "#         clean_tokens_arr_ = clean_tokens_arr[[\n",
    "#             not(item) for item in map(func, clean_tokens_arr)\n",
    "#         ]]\n",
    "#     except TypeError:  # TypeError: iteration over a 0-d array\n",
    "#         return clean_tokens_arr\n",
    "#     else:\n",
    "#         return clean_tokens_arr_\n",
    "    \n",
    "    return clean_tokens_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_word(text):\n",
    "    \"\"\"Tokenizes text row by row from pandas DataFrame.\n",
    "\n",
    "    Tokenizes text by this function combine tokenize method \n",
    "    from nltk package and some self-defined rules. It may fail\n",
    "    when strings out of range of the defined rules occur in text.\n",
    "\n",
    "    Args:\n",
    "        text: A row text data from the relevant column of pandas \n",
    "        DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        A numpy array containing clean tokens extracted from text\n",
    "\n",
    "        \"we were friends, good friends\" --> ['we', 'were', 'friend', 'good', 'friend']\n",
    "\n",
    "    Raises:\n",
    "        None yet\n",
    "    \"\"\"\n",
    "    \n",
    "    url_reg = \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "    punct_reg = \"[^a-zA-Z0-9@]+\"\n",
    "#     punct_reg = \"[^a-zA-Z0-9]+\"\n",
    "    detected_urls = re.findall(url_reg, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "    text = re.sub(punct_reg, \" \", text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    word_tokenizer_tweet = TweetTokenizer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    tokens = word_tokenizer_tweet.tokenize(text)\n",
    "    clean_tokens_list = [lemmatizer.lemmatize(tok).strip() for tok in tokens]\n",
    "#     clean_tokens_list = [lemmatizer.lemmatize(stemmer(tok)).strip() for tok in tokens]  \n",
    "    \n",
    "    # Note 2019/3/7: remove any text followed by  \"@\",  fail because unsolved Error \"TypeError: iteration over a 0-d array \"\n",
    "#     clean_tokens_arr = np.array(clean_tokens_list).squeeze()\n",
    "#     func = lambda x: \"@\" in x\n",
    "#     try:\n",
    "#         clean_tokens_arr_ = clean_tokens_arr[[\n",
    "#             not(item) for item in map(func, clean_tokens_arr)\n",
    "#         ]]\n",
    "#     except TypeError:\n",
    "#         return clean_tokens_arr\n",
    "#     else:\n",
    "#         return clean_tokens_arr_\n",
    "    for ind, tok in enumerate(clean_tokens_list):\n",
    "        if \"@\" in tok:\n",
    "            del clean_tokens_list[ind]\n",
    "        \n",
    "    return clean_tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['we', 'were', 'friend', 'good', 'friend', 'wont', 't', 'we', 'i',\n",
       "       'hpe', 'this', 'is', 'true', '123'], \n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_sent(\"we were friends, good friends. wont't we? I hpe this is true @123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'i', 'am', 'fine', 'the', 'sun', 'is', 'really', 'warm', 'and', 'happy']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_word(\"hi i am fine. The sun is really warm and happy! @everyone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize_word)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ])),\n",
    "        ])),\n",
    "\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier(n_estimators=100, min_samples_split=3)))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text_pipeline', Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_d...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "related                   0.798347\n",
       "request                   0.881755\n",
       "offer                     0.995931\n",
       "aid_related               0.735919\n",
       "medical_help              0.925111\n",
       "medical_products          0.950922\n",
       "search_and_rescue         0.971011\n",
       "security                  0.981945\n",
       "military                  0.966052\n",
       "child_alone               1.000000\n",
       "water                     0.950286\n",
       "food                      0.919644\n",
       "shelter                   0.923840\n",
       "clothing                  0.985124\n",
       "money                     0.976987\n",
       "missing_people            0.988303\n",
       "refugees                  0.967196\n",
       "death                     0.958423\n",
       "other_aid                 0.870947\n",
       "infrastructure_related    0.936300\n",
       "transport                 0.957406\n",
       "buildings                 0.951430\n",
       "electricity               0.979402\n",
       "tools                     0.994024\n",
       "hospitals                 0.989320\n",
       "shops                     0.996186\n",
       "aid_centers               0.989320\n",
       "other_infrastructure      0.957661\n",
       "weather_related           0.840559\n",
       "floods                    0.936936\n",
       "storm                     0.928290\n",
       "fire                      0.989574\n",
       "earthquake                0.961729\n",
       "cold                      0.982708\n",
       "other_weather             0.946472\n",
       "direct_report             0.850477\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use default parameters of clf\n",
    "\n",
    "\n",
    "(Y_test == Y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "related                   0.804069\n",
       "request                   0.895232\n",
       "offer                     0.996058\n",
       "aid_related               0.783217\n",
       "medical_help              0.926891\n",
       "medical_products          0.950286\n",
       "search_and_rescue         0.971011\n",
       "security                  0.981945\n",
       "military                  0.965798\n",
       "child_alone               1.000000\n",
       "water                     0.951939\n",
       "food                      0.923586\n",
       "shelter                   0.932104\n",
       "clothing                  0.984743\n",
       "money                     0.977622\n",
       "missing_people            0.988175\n",
       "refugees                  0.966561\n",
       "death                     0.957788\n",
       "other_aid                 0.872473\n",
       "infrastructure_related    0.937190\n",
       "transport                 0.959186\n",
       "buildings                 0.950286\n",
       "electricity               0.979275\n",
       "tools                     0.994024\n",
       "hospitals                 0.989320\n",
       "shops                     0.996186\n",
       "aid_centers               0.989320\n",
       "other_infrastructure      0.957661\n",
       "weather_related           0.876923\n",
       "floods                    0.951558\n",
       "storm                     0.940242\n",
       "fire                      0.989828\n",
       "earthquake                0.966306\n",
       "cold                      0.981564\n",
       "other_weather             0.947870\n",
       "direct_report             0.866370\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use specific parameters of clf as \"n_estimators=100, min_samples_split=3\"\n",
    "\n",
    "(Y_test == Y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Check metrics for feature named as related----------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " related_true       0.64      0.35      0.46      1829\n",
      "related_false       0.82      0.94      0.88      5977\n",
      "\n",
      "  avg / total       0.78      0.80      0.78      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as request----------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " request_true       0.89      0.98      0.93      6524\n",
      "request_false       0.83      0.38      0.53      1341\n",
      "\n",
      "  avg / total       0.88      0.88      0.86      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as offer----------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " offer_true       1.00      1.00      1.00      7834\n",
      "offer_false       0.00      0.00      0.00        31\n",
      "\n",
      "avg / total       0.99      1.00      0.99      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as aid_related----------\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " aid_related_true       0.73      0.87      0.79      4609\n",
      "aid_related_false       0.75      0.54      0.63      3256\n",
      "\n",
      "      avg / total       0.74      0.74      0.73      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as medical_help----------\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      " medical_help_true       0.93      1.00      0.96      7269\n",
      "medical_help_false       0.55      0.06      0.11       596\n",
      "\n",
      "       avg / total       0.90      0.93      0.90      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as medical_products----------\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      " medical_products_true       0.95      1.00      0.97      7463\n",
      "medical_products_false       0.74      0.06      0.11       402\n",
      "\n",
      "           avg / total       0.94      0.95      0.93      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as search_and_rescue----------\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      " search_and_rescue_true       0.97      1.00      0.99      7634\n",
      "search_and_rescue_false       0.80      0.02      0.03       231\n",
      "\n",
      "            avg / total       0.97      0.97      0.96      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as security----------\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " security_true       0.98      1.00      0.99      7725\n",
      "security_false       0.00      0.00      0.00       140\n",
      "\n",
      "   avg / total       0.96      0.98      0.97      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as military----------\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " military_true       0.97      1.00      0.98      7592\n",
      "military_false       0.62      0.06      0.11       273\n",
      "\n",
      "   avg / total       0.96      0.97      0.95      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as child_alone----------\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " child_alone_true       1.00      1.00      1.00      7865\n",
      "\n",
      "      avg / total       1.00      1.00      1.00      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as water----------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " water_true       0.95      1.00      0.97      7375\n",
      "water_false       0.89      0.23      0.37       490\n",
      "\n",
      "avg / total       0.95      0.95      0.94      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as food----------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  food_true       0.92      0.99      0.96      6949\n",
      " food_false       0.84      0.38      0.52       916\n",
      "\n",
      "avg / total       0.91      0.92      0.91      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as shelter----------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " shelter_true       0.93      0.99      0.96      7164\n",
      "shelter_false       0.79      0.20      0.32       701\n",
      "\n",
      "  avg / total       0.91      0.92      0.90      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as clothing----------\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " clothing_true       0.99      1.00      0.99      7740\n",
      "clothing_false       0.72      0.10      0.18       125\n",
      "\n",
      "   avg / total       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as money----------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " money_true       0.98      1.00      0.99      7681\n",
      "money_false       0.71      0.03      0.05       184\n",
      "\n",
      "avg / total       0.97      0.98      0.97      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as missing_people----------\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      " missing_people_true       0.99      1.00      0.99      7774\n",
      "missing_people_false       0.00      0.00      0.00        91\n",
      "\n",
      "         avg / total       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as refugees----------\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " refugees_true       0.97      1.00      0.98      7605\n",
      "refugees_false       0.54      0.05      0.09       260\n",
      "\n",
      "   avg / total       0.95      0.97      0.95      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as death----------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " death_true       0.96      1.00      0.98      7497\n",
      "death_false       0.83      0.14      0.24       368\n",
      "\n",
      "avg / total       0.95      0.96      0.94      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as other_aid----------\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " other_aid_true       0.87      1.00      0.93      6848\n",
      "other_aid_false       0.52      0.03      0.06      1017\n",
      "\n",
      "    avg / total       0.83      0.87      0.82      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as infrastructure_related----------\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      " infrastructure_related_true       0.94      1.00      0.97      7371\n",
      "infrastructure_related_false       0.18      0.00      0.01       494\n",
      "\n",
      "                 avg / total       0.89      0.94      0.91      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as transport----------\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " transport_true       0.96      1.00      0.98      7526\n",
      "transport_false       0.57      0.05      0.09       339\n",
      "\n",
      "    avg / total       0.94      0.96      0.94      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as buildings----------\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " buildings_true       0.95      1.00      0.97      7452\n",
      "buildings_false       0.72      0.12      0.21       413\n",
      "\n",
      "    avg / total       0.94      0.95      0.93      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as electricity----------\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " electricity_true       0.98      1.00      0.99      7696\n",
      "electricity_false       0.77      0.06      0.11       169\n",
      "\n",
      "      avg / total       0.98      0.98      0.97      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as tools----------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " tools_true       0.99      1.00      1.00      7818\n",
      "tools_false       0.00      0.00      0.00        47\n",
      "\n",
      "avg / total       0.99      0.99      0.99      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as hospitals----------\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " hospitals_true       0.99      1.00      0.99      7781\n",
      "hospitals_false       0.00      0.00      0.00        84\n",
      "\n",
      "    avg / total       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as shops----------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " shops_true       1.00      1.00      1.00      7835\n",
      "shops_false       0.00      0.00      0.00        30\n",
      "\n",
      "avg / total       0.99      1.00      0.99      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as aid_centers----------\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " aid_centers_true       0.99      1.00      0.99      7781\n",
      "aid_centers_false       0.00      0.00      0.00        84\n",
      "\n",
      "      avg / total       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as other_infrastructure----------\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      " other_infrastructure_true       0.96      1.00      0.98      7533\n",
      "other_infrastructure_false       0.40      0.01      0.01       332\n",
      "\n",
      "               avg / total       0.93      0.96      0.94      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as weather_related----------\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      " weather_related_true       0.84      0.96      0.90      5691\n",
      "weather_related_false       0.82      0.54      0.65      2174\n",
      "\n",
      "          avg / total       0.84      0.84      0.83      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as floods----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " floods_true       0.94      1.00      0.97      7215\n",
      "floods_false       0.89      0.27      0.42       650\n",
      "\n",
      " avg / total       0.93      0.94      0.92      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as storm----------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " storm_true       0.94      0.98      0.96      7140\n",
      "storm_false       0.70      0.38      0.50       725\n",
      "\n",
      "avg / total       0.92      0.93      0.92      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as fire----------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  fire_true       0.99      1.00      0.99      7784\n",
      " fire_false       0.00      0.00      0.00        81\n",
      "\n",
      "avg / total       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as earthquake----------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " earthquake_true       0.97      0.99      0.98      7116\n",
      "earthquake_false       0.88      0.69      0.77       749\n",
      "\n",
      "     avg / total       0.96      0.96      0.96      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as cold----------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cold_true       0.98      1.00      0.99      7712\n",
      " cold_false       0.71      0.19      0.30       153\n",
      "\n",
      "avg / total       0.98      0.98      0.98      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as other_weather----------\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      " other_weather_true       0.95      1.00      0.97      7446\n",
      "other_weather_false       0.45      0.02      0.05       419\n",
      "\n",
      "        avg / total       0.92      0.95      0.92      7865\n",
      "\n",
      "\n",
      "----------Check metrics for feature named as direct_report----------\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      " direct_report_true       0.86      0.98      0.91      6359\n",
      "direct_report_false       0.79      0.30      0.44      1506\n",
      "\n",
      "        avg / total       0.84      0.85      0.82      7865\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 3, does not match size of target_names, 2\n",
      "  .format(len(labels), len(target_names))\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 1, does not match size of target_names, 2\n",
      "  .format(len(labels), len(target_names))\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for ind, each_col in enumerate(Y_test.columns):\n",
    "    print(\"----------Check metrics for feature named as {}----------\".format(each_col))\n",
    "    print(classification_report(Y_test.loc[:, each_col], Y_pred[:, ind], target_names=[each_col+\"_true\", each_col+\"_false\"]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "from contextlib import contextmanager\n",
    "import requests\n",
    "\n",
    "DELAY = INTERVAL = 4 * 60  # interval time in seconds\n",
    "MIN_DELAY = MIN_INTERVAL = 2 * 60\n",
    "KEEPALIVE_URL = \"https://nebula.udacity.com/api/v1/remote/keep-alive\"\n",
    "TOKEN_URL = \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\"\n",
    "TOKEN_HEADERS = {\"Metadata-Flavor\":\"Google\"}\n",
    "\n",
    "\n",
    "def _request_handler(headers):\n",
    "    def _handler(signum, frame):\n",
    "        requests.request(\"POST\", KEEPALIVE_URL, headers=headers)\n",
    "    return _handler\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def active_session(delay=DELAY, interval=INTERVAL):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "\n",
    "    from workspace_utils import active session\n",
    "\n",
    "    with active_session():\n",
    "        # do long-running work here\n",
    "    \"\"\"\n",
    "    token = requests.request(\"GET\", TOKEN_URL, headers=TOKEN_HEADERS).text\n",
    "    headers = {'Authorization': \"STAR \" + token}\n",
    "    delay = max(delay, MIN_DELAY)\n",
    "    interval = max(interval, MIN_INTERVAL)\n",
    "    original_handler = signal.getsignal(signal.SIGALRM)\n",
    "    try:\n",
    "        signal.signal(signal.SIGALRM, _request_handler(headers))\n",
    "        signal.setitimer(signal.ITIMER_REAL, delay, interval)\n",
    "        yield\n",
    "    finally:\n",
    "        signal.signal(signal.SIGALRM, original_handler)\n",
    "        signal.setitimer(signal.ITIMER_REAL, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'features__text_pipeline__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "#         'features__text_pipeline__vect__max_df': (0.5, 0.75, 1.0),\n",
    "        'features__text_pipeline__vect__max_features': (None, 5000, 10000),\n",
    "#         'features__text_pipeline__tfidf__use_idf': (True, False),\n",
    "        'features__transformer_weights': (\n",
    "            {'text_pipeline': 1, 'starting_verb': 0.5},\n",
    "            {'text_pipeline': 0.5, 'starting_verb': 1},\n",
    "            {'text_pipeline': 0.8, 'starting_verb': 1},\n",
    "        )\n",
    "    }\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with active_session():\n",
    "    cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "with active_session():\n",
    "    joblib.dump(cv, 'DisasterResponse_gcv.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Y_test == Y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, each_col in enumerate(Y_test.columns):\n",
    "    print(\"----------Check metrics for feature named as {}----------\".format(each_col))\n",
    "    print(classification_report(Y_test.loc[:, each_col], Y_pred[:, ind], target_names=[each_col+\"_true\", each_col+\"_false\"]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2019/3/8: update all descriptions here\n",
    "\n",
    "\n",
    "def number_normalizer(tokens):\n",
    "    \"\"\" Map all numeric tokens to a placeholder.\n",
    "\n",
    "    For many applications, tokens that begin with a number are not directly\n",
    "    useful, but the fact that such a token exists can be relevant.  By applying\n",
    "    this form of dimensionality reduction, some methods may perform better.\n",
    "\n",
    "    Args:\n",
    "        text: A row text data from the relevant column of pandas \n",
    "        DataFrame\n",
    "            \n",
    "    Returns:\n",
    "        A numpy array containing clean tokens extracted from text\n",
    "\n",
    "        \"we were friends, good friends\" --> ['we', 'were', 'friend', 'good', 'friend']\n",
    "\n",
    "    Raises:\n",
    "        None yet\n",
    "    \"\"\"\n",
    "    return (\"numberplaceholder\" if token[0].isdigit() else token for token in tokens)\n",
    "\n",
    "\n",
    "def tokenize_word(text):\n",
    "    \"\"\"Tokenizes text row by row from pandas DataFrame.\n",
    "\n",
    "    Tokenizes text by this function combine tokenize method \n",
    "    from nltk package and some self-defined rules. It may fail\n",
    "    when strings out of range of the defined rules occur in text.\n",
    "\n",
    "    Args:\n",
    "        text: A row text data from the relevant column of pandas \n",
    "        DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        A numpy array containing clean tokens extracted from text\n",
    "\n",
    "        \"we were friends, good friends\" --> ['we', 'were', 'friend', 'good', 'friend']\n",
    "\n",
    "    Raises:\n",
    "        None yet\n",
    "    \"\"\"\n",
    "    \n",
    "    url_reg = \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "    punct_reg = \"[^a-zA-Z0-9@]+\"\n",
    "    detected_urls = re.findall(url_reg, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "    text = re.sub(punct_reg, \" \", text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    word_tokenizer_tweet = TweetTokenizer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    tokens = word_tokenizer_tweet.tokenize(text)\n",
    "    tokens = number_normalizer(tokens)\n",
    "    clean_tokens_list = [lemmatizer.lemmatize(stemmer.stem(tok)).strip() for tok in tokens]  \n",
    "\n",
    "    for ind, tok in enumerate(clean_tokens_list):\n",
    "        if \"@\" in tok:\n",
    "            del clean_tokens_list[ind]\n",
    "        \n",
    "    return clean_tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2019/3/9: construct to deal with the error\n",
    "\n",
    "\n",
    "# class ExpandForBalance(BaseEstimator, TransformerMixin):\n",
    "#     \"\"\"Summary of class here.\n",
    "\n",
    "#     Longer class information....\n",
    "#     Longer class information....\n",
    "\n",
    "#     Attributes:\n",
    "#         likes_spam: A boolean indicating if we like SPAM or not.\n",
    "#         eggs: An integer count of the eggs we have laid.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def starting_verb(self, arr):\n",
    "#         \"\"\"Inits SampleClass with blah.\"\"\"\n",
    "        \n",
    "#         return False\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         \"\"\"Inits SampleClass with blah.\"\"\"        \n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         \"\"\"Inits SampleClass with blah.\"\"\"        \n",
    "#         X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "#         return pd.DataFrame([X, X_count, X_std, X_mean, X_sum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for each_col in Y.columns:\n",
    "    print(Y.loc[:, each_col].value_counts().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X)\n",
    "X_df = X_df.drop((Y[Y.loc[:, \"related\"] == 2]).index).reset_index(drop=True)\n",
    "Y = Y.drop((Y[Y.loc[:, \"related\"] == 2]).index).reset_index(drop=True)\n",
    "\n",
    "X_train_df, X_test_df, Y_train, Y_test = train_test_split(X_df, Y, test_size=0.2, shuffle=True)\n",
    "X_train_part_df, X_valid_df, Y_train_part, Y_valid = train_test_split(X_train_df, Y_train, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://lightgbm.readthedocs.io/en/latest/\n",
    "\n",
    "params = {\n",
    "          'boosting_type': 'rf',\n",
    "          'num_leaves': 70, \n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.008,\n",
    "          'n_estimators': 100,\n",
    "          'subsample_for_bin': 200000,\n",
    "          'objective': 'binary',\n",
    "          'class_weight': None,\n",
    "          'min_split_gain': 0,\n",
    "          'min_child_weight': 0,\n",
    "          'min_child_samples': 35,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 0,\n",
    "          'colsample_bytree': 1,\n",
    "          'reg_alpha': 0.11,  # L1 reg\n",
    "          'reg_lambda': 0.5,  # L2 reg\n",
    "          'random_state': 23,\n",
    "          'n_jobs': 3,\n",
    "          'silent': False,\n",
    "          'importance_type': 'split',\n",
    "\n",
    "          \"feature_fraction\": 0.85,\n",
    "          \"bagging_freq\": 1,\n",
    "          \"bagging_fraction\": 0.82,\n",
    "          \"bagging_seed\": 42,\n",
    "          \"metric_freq\": 200,\n",
    "          \"early_stopping_round\": 150,\n",
    "          \"num_iterations\": 10000,\n",
    "#           \"is_unbalance\": True,  # used only in `binary` application\n",
    "         \n",
    "          \"num_class\": 1\n",
    "         }\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize_word)),\n",
    "                ('tfidf', TfidfTransformer()), \n",
    "#                 ('expand', ExpandForBalance())  # TODO 2019/3/9: add new transformation to deal with the error\n",
    "            ])),\n",
    "             \n",
    "        ])),\n",
    "    \n",
    "        ('clf', lgb.LGBMClassifier(**params))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (16657, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-9b0dcc2eb557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         **{\n\u001b[1;32m     14\u001b[0m                 \u001b[0;34m'clf__eval_set'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid_each\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Note 2019/3/9: use numpy array to avoid the check failue of X shape by sklearn.utils: validation.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;34m'clf__eval_metric'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'binary_logloss'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         }\n\u001b[1;32m     17\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0m_LGBMAssertAllFinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0m_LGBMCheckClassificationTargets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LGBMLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \"\"\"\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (16657, 2)"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "Y_pred = {each_col:0 for each_col in Y_train.columns}\n",
    "\n",
    "for ind, each_col in enumerate(Y_train.columns):\n",
    "    Y_train_part_each = to_categorical(Y_train_part.loc[:, each_col], 2)\n",
    "    Y_valid_each = to_categorical(Y_valid.loc[:, each_col], 2)\n",
    "    \n",
    "    \n",
    "    pipeline.fit(\n",
    "        X_train_part_df.values[:, 0],   # Note 2019/3/9: use numpy array to avoid the check failue of X shape by sklearn.utils: validation.py\n",
    "        Y_train_part_each, \n",
    "        **{\n",
    "                'clf__eval_set': [(X_valid_df.values[:, 0], Y_valid_each)],  # Note 2019/3/9: use numpy array to avoid the check failue of X shape by sklearn.utils: validation.py\n",
    "                'clf__eval_metric': 'binary_logloss'\n",
    "        }\n",
    "    )\n",
    "    Y_pred[each_col] = pipeline.predict(X_test)\n",
    "    print(\"Finish the train of {} feature\".format(ind+1))\n",
    "\n",
    "Y_pred_df = pd.DataFrame(Y_pred)\n",
    "    \n",
    "# for ind, each_col in enumerate(Y_test.columns):\n",
    "#     print(\"----------Check metrics for feature named as {}----------\".format(each_col))\n",
    "#     print(classification_report(Y_test.loc[:, each_col], Y_pred[:, ind], target_names=[each_col+\"_true\", each_col+\"_false\"]))\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-09 11:13:12,163 : INFO : collecting all words and their counts\n",
      "2019-03-09 11:13:12,172 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-09 11:13:12,929 : INFO : PROGRESS: at sentence #10000, processed 219770 words, keeping 23488 word types\n",
      "2019-03-09 11:13:13,616 : INFO : PROGRESS: at sentence #20000, processed 430477 words, keeping 34367 word types\n",
      "2019-03-09 11:13:14,377 : INFO : PROGRESS: at sentence #30000, processed 669056 words, keeping 42365 word types\n",
      "2019-03-09 11:13:15,069 : INFO : PROGRESS: at sentence #40000, processed 888291 words, keeping 49136 word types\n",
      "2019-03-09 11:13:15,616 : INFO : PROGRESS: at sentence #50000, processed 1039920 words, keeping 53024 word types\n",
      "2019-03-09 11:13:16,041 : INFO : collected 56057 word types from a corpus of 1161192 raw words and 57340 sentences\n",
      "2019-03-09 11:13:16,045 : INFO : Loading a fresh vocabulary\n",
      "2019-03-09 11:13:16,202 : INFO : min_count=1 retains 56057 unique words (100% of original 56057, drops 0)\n",
      "2019-03-09 11:13:16,206 : INFO : min_count=1 leaves 1161192 word corpus (100% of original 1161192, drops 0)\n",
      "2019-03-09 11:13:16,379 : INFO : deleting the raw counts dictionary of 56057 items\n",
      "2019-03-09 11:13:16,383 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2019-03-09 11:13:16,387 : INFO : downsampling leaves estimated 854152 word corpus (73.6% of prior 1161192)\n",
      "2019-03-09 11:13:16,621 : INFO : estimated required memory for 56057 words and 100 dimensions: 72874100 bytes\n",
      "2019-03-09 11:13:16,625 : INFO : resetting layer weights\n",
      "2019-03-09 11:13:17,306 : INFO : training model with 3 workers on 56057 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-03-09 11:13:18,330 : INFO : EPOCH 1 - PROGRESS: at 13.91% examples, 123620 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:19,342 : INFO : EPOCH 1 - PROGRESS: at 28.72% examples, 127587 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:20,342 : INFO : EPOCH 1 - PROGRESS: at 42.97% examples, 131041 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:21,342 : INFO : EPOCH 1 - PROGRESS: at 56.89% examples, 133037 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:22,387 : INFO : EPOCH 1 - PROGRESS: at 73.02% examples, 133093 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:23,394 : INFO : EPOCH 1 - PROGRESS: at 92.39% examples, 131593 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:23,800 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-09 11:13:23,814 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-09 11:13:23,825 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-09 11:13:23,828 : INFO : EPOCH - 1 : training on 1161192 raw words (853954 effective words) took 6.5s, 131026 effective words/s\n",
      "2019-03-09 11:13:24,876 : INFO : EPOCH 2 - PROGRESS: at 14.64% examples, 128102 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:25,913 : INFO : EPOCH 2 - PROGRESS: at 30.18% examples, 131859 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:26,930 : INFO : EPOCH 2 - PROGRESS: at 44.52% examples, 133179 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:27,938 : INFO : EPOCH 2 - PROGRESS: at 58.31% examples, 134405 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:28,990 : INFO : EPOCH 2 - PROGRESS: at 75.14% examples, 133976 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:30,003 : INFO : EPOCH 2 - PROGRESS: at 93.29% examples, 131069 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:30,355 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-09 11:13:30,369 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-09 11:13:30,381 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-09 11:13:30,385 : INFO : EPOCH - 2 : training on 1161192 raw words (854917 effective words) took 6.6s, 130481 effective words/s\n",
      "2019-03-09 11:13:31,394 : INFO : EPOCH 3 - PROGRESS: at 13.09% examples, 118051 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:32,416 : INFO : EPOCH 3 - PROGRESS: at 27.01% examples, 120603 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:33,456 : INFO : EPOCH 3 - PROGRESS: at 41.53% examples, 124829 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:34,491 : INFO : EPOCH 3 - PROGRESS: at 54.57% examples, 125385 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:35,514 : INFO : EPOCH 3 - PROGRESS: at 69.81% examples, 127517 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:36,522 : INFO : EPOCH 3 - PROGRESS: at 89.23% examples, 126922 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:37,087 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-09 11:13:37,099 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-09 11:13:37,108 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-09 11:13:37,111 : INFO : EPOCH - 3 : training on 1161192 raw words (853828 effective words) took 6.7s, 127016 effective words/s\n",
      "2019-03-09 11:13:38,118 : INFO : EPOCH 4 - PROGRESS: at 13.09% examples, 118504 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:39,142 : INFO : EPOCH 4 - PROGRESS: at 27.01% examples, 120664 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:40,168 : INFO : EPOCH 4 - PROGRESS: at 41.53% examples, 125458 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:41,212 : INFO : EPOCH 4 - PROGRESS: at 55.32% examples, 127345 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:42,214 : INFO : EPOCH 4 - PROGRESS: at 69.81% examples, 128206 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:43,242 : INFO : EPOCH 4 - PROGRESS: at 89.23% examples, 127069 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:43,809 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-09 11:13:43,822 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-09 11:13:43,832 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-09 11:13:43,836 : INFO : EPOCH - 4 : training on 1161192 raw words (853993 effective words) took 6.7s, 127088 effective words/s\n",
      "2019-03-09 11:13:44,844 : INFO : EPOCH 5 - PROGRESS: at 13.09% examples, 118233 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:45,870 : INFO : EPOCH 5 - PROGRESS: at 27.01% examples, 120450 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:46,922 : INFO : EPOCH 5 - PROGRESS: at 40.69% examples, 121895 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:47,978 : INFO : EPOCH 5 - PROGRESS: at 53.82% examples, 122542 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:49,038 : INFO : EPOCH 5 - PROGRESS: at 67.44% examples, 122993 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:50,058 : INFO : EPOCH 5 - PROGRESS: at 85.91% examples, 121685 words/s, in_qsize 0, out_qsize 0\n",
      "2019-03-09 11:13:50,859 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-09 11:13:50,878 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-09 11:13:50,887 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-09 11:13:50,890 : INFO : EPOCH - 5 : training on 1161192 raw words (854096 effective words) took 7.0s, 121163 effective words/s\n",
      "2019-03-09 11:13:50,891 : INFO : training on a 5805960 raw words (4270788 effective words) took 33.6s, 127179 effective words/s\n",
      "2019-03-09 11:13:50,893 : INFO : saving Word2Vec object under brown_model, separately None\n",
      "2019-03-09 11:13:50,896 : INFO : not storing attribute vectors_norm\n",
      "2019-03-09 11:13:50,898 : INFO : not storing attribute cum_table\n",
      "2019-03-09 11:13:51,704 : INFO : saved brown_model\n"
     ]
    }
   ],
   "source": [
    "with active_session():\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    sentences = brown.sents()\n",
    "    model = gensim.models.Word2Vec(sentences, min_count=1)\n",
    "    model.save('brown_model')\n",
    "#     model = gensim.models.Word2Vec.load('brown_model')\n",
    "\n",
    "# model['computer']  # raw NumPy vector of a requested word, for this example the array is something like this \"array([-0.00449447, -0.00310097,  0.02421786, ...], dtype=float32)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "# model = pickle.dumps(pipeline)\n",
    "# fw = open('DisasterResponse_model.txt',' w')\n",
    "# fw.write(model)\n",
    "# fw.close()\n",
    "# fr = open('DisasterResponse_model.txt', 'r')\n",
    "# model = pickle.loads(fr.read())\n",
    "\n",
    "joblib.dump(pipeline, 'DisasterResponse_model.pkl')\n",
    "# model = joblib.load('DisasterResponse_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
